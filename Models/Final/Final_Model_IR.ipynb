{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fgzraZGrt-z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7eLjWu3q7F6"
   },
   "source": [
    "## Download KITTI\n",
    "#### http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osmDdpYvBUAX"
   },
   "source": [
    "## Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmlyUo1n6Kfv"
   },
   "outputs": [],
   "source": [
    "class KITTI(Dataset):\n",
    "    def __init__(self, path, transform=None, train = True):\n",
    "        self.transform = transform\n",
    "        self.img0_dir = path + \"train_set/left/\"\n",
    "        self.img1_dir = path + \"train_set/right/\"\n",
    "        self.gt_dir = path + \"train_set/disp/\"\n",
    "        self.train = train\n",
    "        if train:\n",
    "          self.size = int(len(os.listdir(self.gt_dir))*0.8)\n",
    "        else:\n",
    "          self.size = int(len(os.listdir(self.gt_dir))*0.2)\n",
    "          self.remainder = int(len(os.listdir(self.gt_dir))*0.8)\n",
    "          \n",
    "        self.h = 256\n",
    "        self.w = 416\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "          img0_path = self.img0_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          img1_path = self.img1_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          gt_path = self.gt_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          img0 = Image.open(img0_path).convert('RGB')\n",
    "          img1 = Image.open(img1_path).convert('RGB')\n",
    "          gt = np.ascontiguousarray(Image.open(gt_path), dtype=np.float32)\n",
    "          w,h  = img0.size\n",
    "          self.r_h = random.randint(0,h-self.h)\n",
    "          self.r_w = random.randint(0,w-self.w)\n",
    "          img0 = img0.crop((self.r_w,self.r_h, self.r_w + self.w,self.r_h + self.h))\n",
    "          img1 = img1.crop((self.r_w,self.r_h, self.r_w + self.w,self.r_h + self.h))\n",
    "          gt =  gt[self.r_h:self.r_h+self.h, self.r_w:self.r_w + self.w ]\n",
    "          if self.transform:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "          return img0, img1, gt\n",
    "        else:\n",
    "          idx += self.remainder\n",
    "          img0_path = self.img0_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          img1_path = self.img1_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          gt_path = self.gt_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          img0 = Image.open(img0_path).convert('RGB')\n",
    "          img1 = Image.open(img1_path).convert('RGB')\n",
    "          w,h  = img0.size\n",
    "          img0 = img0.crop((w-416, h-320, w, h))\n",
    "          img1 = img1.crop((w-416, h-320, w, h))\n",
    "          gt = Image.open(gt_path)\n",
    "          gt = gt.crop((w-416, h-320, w, h))\n",
    "          gt = np.ascontiguousarray(gt,dtype=np.float32)\n",
    "          if self.transform:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "          return img0, img1, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJau0hed6Dz-",
    "outputId": "8bb26563-37ce-4a03-de38-0d255eefccdd"
   },
   "outputs": [],
   "source": [
    "normalize = {'mean': [0.485, 0.456, 0.406],\n",
    "                   'std': [0.229, 0.224, 0.225]}\n",
    "input_transforms = torchvision.transforms.Compose([transforms.ToTensor()])\n",
    "test_dataset = KITTI('./CMU_CLEAN/', transform=input_transforms, train = False)\n",
    "test_Loader = DataLoader(test_dataset, batch_size= 1, shuffle= False, num_workers= 4, drop_last=False)\n",
    "print('Test Dataset Size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CTKI2o3Vr_i",
    "outputId": "f9d417a9-8017-4e0a-b272-3757e6e9088e"
   },
   "outputs": [],
   "source": [
    "train_dataset = KITTI('./CMU_CLEAN/', transform=input_transforms,train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, pin_memory=True, shuffle=True, num_workers=4)\n",
    "\n",
    "print('Train Dataset Size:', len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxC1EFWbG_T5"
   },
   "source": [
    "## Create Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVo8MjkL0D5P"
   },
   "outputs": [],
   "source": [
    "def conv_bn(dim, in_planes, out_planes, kernel_size, stride, pad, dilation=None):\n",
    "  if dim == 2:\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_planes, out_channels=out_planes, kernel_size=kernel_size, stride=stride, padding=dilation if dilation > 1 else pad, dilation=dilation, bias=False),\n",
    "        nn.BatchNorm2d(out_planes)\n",
    "    )\n",
    "  elif dim == 3:\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_channels=in_planes, out_channels=out_planes, kernel_size=kernel_size, padding=pad, stride=stride, bias=False),\n",
    "        nn.BatchNorm3d(out_planes)\n",
    "    )  \n",
    "\n",
    "class DisparityRegression(nn.Module):\n",
    "  def __init__(self, max_disp):\n",
    "    super(DisparityRegression, self).__init__()\n",
    "    self.disp = Variable(torch.Tensor(np.reshape(np.array(range(max_disp)), [1, max_disp, 1, 1])).cuda(), requires_grad=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    disp = self.disp.repeat(x.size()[0], 1, x.size()[2], x.size()[3])\n",
    "    out = torch.sum(x*disp, 1)\n",
    "\n",
    "    return out\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv_sc = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.bn_sc = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        y = F.relu(self.bn2(self.conv2(y)))\n",
    "        y = self.bn3(self.conv3(y))\n",
    "\n",
    "        x = self.conv_sc(x)\n",
    "        x = self.bn_sc(x)\n",
    "\n",
    "        y += x\n",
    "        y = F.relu(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        y = self.bn2(self.conv2(y))\n",
    "        y += x\n",
    "        y = F.relu(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class Feature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Sequential(ConvBlock(3,32,3,1),\n",
    "                                  IdentityBlock(32),\n",
    "                                  IdentityBlock(32),\n",
    "                                  IdentityBlock(32),\n",
    "                                  IdentityBlock(32),\n",
    "                                  ConvBlock(32,64,3,1),\n",
    "                                  IdentityBlock(64),\n",
    "                                  IdentityBlock(64),\n",
    "                                  IdentityBlock(64),\n",
    "                                  IdentityBlock(64),\n",
    "                                  )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(ConvBlock(3,32,3,1),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          ConvBlock(32,64,3,1),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(ConvBlock(3,32,3,1),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          ConvBlock(32,64,3,1),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(ConvBlock(3,32,3,1),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          IdentityBlock(32),\n",
    "                          ConvBlock(32,64,3,1),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          IdentityBlock(64),\n",
    "                          )\n",
    "\n",
    "        self.final_conv = nn.Sequential(ConvBlock(64*4, 128, 3, 1),\n",
    "                                        IdentityBlock(128),\n",
    "                                        IdentityBlock(128),\n",
    "                                        IdentityBlock(128),\n",
    "                                        IdentityBlock(128),\n",
    "                                        ConvBlock(128, 64, 3, 1),\n",
    "                                        IdentityBlock(64),\n",
    "                                        IdentityBlock(64),\n",
    "                                        IdentityBlock(64),\n",
    "                                        IdentityBlock(64),\n",
    "                                        nn.Conv2d(64,32,1)\n",
    "                                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(F.avg_pool2d(x, 4))\n",
    "        x2 = self.conv2(F.avg_pool2d(x, 8))\n",
    "        x3 = self.conv3(F.avg_pool2d(x, 16))\n",
    "        x4 = self.conv4(F.avg_pool2d(x, 32))\n",
    "\n",
    "        x2 = F.interpolate(x2, (x1.shape[2], x1.shape[3]), mode = 'bilinear')\n",
    "        x3 = F.interpolate(x3, (x1.shape[2], x1.shape[3]), mode = 'bilinear')\n",
    "        x4 = F.interpolate(x4, (x1.shape[2], x1.shape[3]), mode = 'bilinear')\n",
    "\n",
    "        y = torch.cat((x1,x2,x3,x4), dim=1)\n",
    "        y = F.dropout2d(y)\n",
    "        y = self.final_conv(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cm6c7Xhf8Is3"
   },
   "outputs": [],
   "source": [
    "class PSMNet(nn.Module):\n",
    "  def __init__(self, max_disp):\n",
    "    super(PSMNet, self).__init__()\n",
    "    self.maxdisp = max_disp\n",
    "    self.feature_extraction = Feature()\n",
    "\n",
    "    self.res0 = nn.Sequential(\n",
    "      conv_bn(3, 64, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True)\n",
    "    )\n",
    "    self.res1 = nn.Sequential(\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "    )\n",
    "    self.res2 = nn.Sequential(\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      conv_bn(3, 32, 32, 3, 1, 1)\n",
    "    )\n",
    "    self.res3 = nn.Sequential(\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True), \n",
    "      conv_bn(3, 32, 32, 3, 1, 1)\n",
    "    )\n",
    "    self.res4 = nn.Sequential(\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      conv_bn(3, 32, 32, 3, 1, 1)\n",
    "    )\n",
    "    self.classify = nn.Sequential(\n",
    "      conv_bn(3, 32, 32, 3, 1, 1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "    )\n",
    "\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "      elif isinstance(m, nn.Conv3d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
    "        m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "      elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm3d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "      elif isinstance(m, nn.Linear):\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "  def forward(self, left, right):\n",
    "    ref_img_fea = self.feature_extraction(left)\n",
    "    target_img_fea  = self.feature_extraction(right)\n",
    "\n",
    "    cost = Variable(torch.FloatTensor(ref_img_fea.size()[0], ref_img_fea.size()[1]*2, self.maxdisp//4,  ref_img_fea.size()[2],  ref_img_fea.size()[3]).zero_(), volatile= not self.training).cuda()\n",
    "\n",
    "    for i in range(self.maxdisp//4):\n",
    "      if i > 0:\n",
    "        cost[:, :ref_img_fea.size()[1], i, :,i:] = ref_img_fea[:,:,:,i:]\n",
    "        cost[:, ref_img_fea.size()[1]:, i, :,i:] = target_img_fea[:,:,:,:-i]\n",
    "      else:\n",
    "        cost[:, :ref_img_fea.size()[1], i, :,:] = ref_img_fea\n",
    "        cost[:, ref_img_fea.size()[1]:, i, :,:] = target_img_fea\n",
    "    cost = cost.contiguous()\n",
    "\n",
    "    cost0 = self.res0(cost)\n",
    "    cost0 = self.res1(cost0) + cost0\n",
    "    cost0 = self.res2(cost0) + cost0 \n",
    "    cost0 = self.res3(cost0) + cost0 \n",
    "    cost0 = self.res4(cost0) + cost0\n",
    "\n",
    "    cost = self.classify(cost0)\n",
    "    cost = F.interpolate(cost, [self.maxdisp,left.size()[2], left.size()[3]], mode='trilinear', align_corners=False)\n",
    "    cost = torch.squeeze(cost, 1)\n",
    "    pred = F.softmax(cost)\n",
    "    pred = DisparityRegression(self.maxdisp)(pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3OjAfZXHbce"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYIgp7v3Ha90",
    "outputId": "1563b5b4-534c-4eb9-8960-eb8162aef3cf"
   },
   "outputs": [],
   "source": [
    "# Define network and training parameters\n",
    "torch.cuda.empty_cache()\n",
    "model = PSMNet(192)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "num_epochs = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T37Dam1e6ID3"
   },
   "outputs": [],
   "source": [
    "model = PSMNet(192)\n",
    "model.load_state_dict(torch.load('Model_V2_Epoch_70.pt'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eX7hl07q9axz"
   },
   "outputs": [],
   "source": [
    "def Test_Acc(model2,test_loader):\n",
    "  def test(imgL,imgR,disp_true):\n",
    "\n",
    "        model2.eval()\n",
    "        imgL   = Variable(torch.FloatTensor(imgL))\n",
    "        imgR   = Variable(torch.FloatTensor(imgR))   \n",
    "        imgL, imgR = imgL.cuda(), imgR.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output3 = model2(imgL,imgR)\n",
    "\n",
    "        pred_disp = output3.data.cpu()\n",
    "        true_disp = disp_true.clone()\n",
    "        \n",
    "        array = np.zeros(true_disp.shape)\n",
    "        array[true_disp>0] = 1\n",
    "\n",
    "        greater_than_one = len(array[array==1])\n",
    "\n",
    "        disp_true = np.abs(true_disp-pred_disp.numpy())\n",
    "        disp_true = disp_true*array\n",
    "        error = len(disp_true[disp_true>3])\n",
    "\n",
    "        return float(error)/float(greater_than_one)\n",
    "\n",
    "  Error = []\n",
    "  for i, (imgL, imgR, disp_L) in enumerate(test_Loader):\n",
    "        Error.append(1-test(imgL,imgR,disp_L))\n",
    "\n",
    "  print(f'Final Accuracy: {np.mean(np.array(Error))}')\n",
    "  return np.mean(np.array(Error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8r8zod3Aq0tw",
    "outputId": "945f2332-8d7c-4b40-9fed-368b4e0fc93a"
   },
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params,pytorch_total_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBoP2mVTICCB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train loop\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from google.colab import files\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.05, patience=5, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n",
    "model.train()\n",
    "avg_loss = []\n",
    "start_time = time.time()\n",
    "Acc = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    for i, (imgL, imgR, disp_L) in enumerate(train_loader):\n",
    "      imgL = Variable(torch.FloatTensor(imgL)).to(device)\n",
    "      imgR = Variable(torch.FloatTensor(imgR)).to(device)   \n",
    "      disp_L = Variable(torch.FloatTensor(disp_L)).to(device)\n",
    "\n",
    "      mask = (disp_L > 0)\n",
    "      mask.detach_()\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      out = model(imgL, imgR)\n",
    "      out = torch.squeeze(out, 1)\n",
    "      loss = F.smooth_l1_loss(out[mask], disp_L[mask], size_average=True)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      avg_loss.append(loss.item())\n",
    "      if i%5==0:\n",
    "        print('Epoch: {0}, Iter: {1}, Training Loss: {2}'.format(epoch, i, loss))\n",
    "\n",
    "      total_train_loss += loss.item()\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "      del imgL\n",
    "      del imgR\n",
    "      del disp_L\n",
    "      del out\n",
    "      del loss\n",
    "\n",
    "\n",
    "    scheduler.step(np.mean(avg_loss))\n",
    "    print(f'Scheduler saw loss: {np.mean(avg_loss)}')\n",
    "    print(f'Time: {(time.time()-start_time)/60} \\n') \n",
    "    model.eval()\n",
    "    Acc.append(Test_Acc(model,test_Loader))\n",
    "    \n",
    "    model.train()\n",
    "    if epoch % 10 == 0:\n",
    "      print(f'Saving the model at Epoch: {epoch}, Average Loss: {np.mean(avg_loss)} as Model_V2_Epoch_{epoch}')\n",
    "      torch.save(model.state_dict(), f'Model_V2_Epoch_{epoch}.pt')\n",
    "      #files.download(f'Model_V2_Epoch_{epoch}.pt')\n",
    "      index = [f'Epoch {i}' for i in range(len(Acc))]\n",
    "      Accuracy_Values = {f'Test Accuracy':Acc}\n",
    "#       df_accuracy = pd.DataFrame(Accuracy_Values,index=index)\n",
    "#       df_accuracy.to_csv(f'Accuracy_Values_Epoch_{epoch}.csv')\n",
    "#       files.download(f'Accuracy_Values_Epoch_{epoch}.csv')\n",
    "\n",
    "    avg_loss = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLvFJLbmJLJv"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model_Epoch_{epoch}.pt')\n",
    "torch.save(optimizer.state_dict(), 'optimizer.pt')\n",
    "torch.save(scheduler.state_dict(), 'scheduler.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiT54xRwukWW",
    "outputId": "d3bbe99e-c8a3-4b55-f28e-c4af2a652ee4"
   },
   "outputs": [],
   "source": [
    "model2 = PSMNet(192)\n",
    "model2.load_state_dict(torch.load('model_V1_Epoch_86.pt'));\n",
    "model2.eval()\n",
    "device = torch.device(\"cuda\")\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u1oGoXgamwX",
    "outputId": "c87f3c31-d77e-499f-92b4-2dbafe49cbfd"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg6SeB3QdO0N"
   },
   "outputs": [],
   "source": [
    "class KITTI_submission(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.img0_dir = path + \"training/left/\"\n",
    "        self.img1_dir = path + \"training/right/\"\n",
    "        self.gt_dir = path + \"training/disp/\"\n",
    "        self.size = int(len(os.listdir(self.gt_dir))*0.2)\n",
    "        self.remainder = int(len(os.listdir(self.gt_dir))*0.8)\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    def __getitem__(self, idx):\n",
    "          idx += self.remainder\n",
    "          img0_path = self.img0_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          img1_path = self.img1_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          gt_path = self.gt_dir + str(idx).zfill(6) + \"_10.png\"\n",
    "          img0 = Image.open(img0_path).convert('RGB')\n",
    "          img1 = Image.open(img1_path).convert('RGB')           \n",
    "          w,h  = img0.size\n",
    "          img0 = img0.crop((w-416, h-320, w, h))\n",
    "          img1 = img1.crop((w-416, h-320, w, h))\n",
    "          gt = Image.open(gt_path)\n",
    "          gt = gt.crop((w-416, h-320, w, h))  \n",
    "          gt = np.ascontiguousarray(gt,dtype=np.float32)\n",
    "          if self.transform:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "          return img0, img1, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Se3i1ucYdO0N",
    "outputId": "5147658d-4177-4450-caeb-c3049525a4c3"
   },
   "outputs": [],
   "source": [
    "normalize = {'mean': [0.485, 0.456, 0.406],\n",
    "                   'std': [0.229, 0.224, 0.225]}\n",
    "input_transforms = torchvision.transforms.Compose([transforms.ToTensor(),\n",
    "                                             transforms.Normalize(**normalize)])\n",
    "submission_dataset = KITTI('./CMU_CLEAN/', transform=input_transforms)\n",
    "submission_loader = DataLoader(submission_dataset, batch_size= 1, shuffle= False, num_workers= 4, drop_last=False)\n",
    "print('Test Dataset Size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O-QV4fIdO0N"
   },
   "outputs": [],
   "source": [
    "def predict(i, imgL,imgR, DispL):\n",
    "\n",
    "    model.eval()\n",
    "    imgL   = Variable(torch.FloatTensor(imgL))\n",
    "    imgR   = Variable(torch.FloatTensor(imgR))   \n",
    "    imgL, imgR = imgL.cuda(), imgR.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output3 = model(imgL,imgR)\n",
    "\n",
    "    pred_disp = np.squeeze(output3.data.cpu().numpy())\n",
    "    true_disp = np.squeeze(DispL.data.cpu().numpy())\n",
    "    \n",
    "    pred_disp = Image.fromarray((pred_disp*256).astype('uint16'))\n",
    "    pred_disp.save(\"pred/\"+str(i)+\".png\")\n",
    "    \n",
    "    true_disp = Image.fromarray((true_disp*256).astype('uint16'))\n",
    "    true_disp.save(\"GT/\" + str(i)+\".png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDNQZlbadO0N",
    "outputId": "6944c902-e597-462f-8a53-4fb31a408881"
   },
   "outputs": [],
   "source": [
    "for i, (imgL, imgR, DispL) in enumerate(submission_loader):\n",
    "    print(\"Inferring\",i)\n",
    "    predict(i, imgL, imgR, DispL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "psmreimp_ir.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
