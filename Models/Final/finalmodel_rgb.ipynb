{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "psmreimp_rgb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Environment (conda_pytorch_p36)",
      "language": "python",
      "name": "conda_pytorch_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgzraZGrt-z"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7eLjWu3q7F6"
      },
      "source": [
        "## Download KITTI\n",
        "#### http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T6Ia_cyvDEBI"
      },
      "source": [
        "%%capture\r\n",
        "\r\n",
        "# Download KITTI data\r\n",
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_stereo_flow.zip && unzip data_stereo_flow.zip\r\n",
        "!mkdir KITTI12\r\n",
        "!mv training KITTI12\r\n",
        "!mv testing KITTI12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GhH4GfKFDUpv"
      },
      "source": [
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_scene_flow.zip && unzip data_scene_flow.zip\r\n",
        "!mkdir KITTI15\r\n",
        "!mv training KITTI15\r\n",
        "!mv testing KITTI15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LkPnY0DGDkYy"
      },
      "source": [
        "img_id = 10\r\n",
        "img = Image.open(\"./KITTI15/training/image_2/\"+str(img_id).zfill(6)+\"_10.png\")\r\n",
        "display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UVoWlv7aDowa"
      },
      "source": [
        "import shutil\r\n",
        "import os\r\n",
        "for idx in range(194):\r\n",
        "  img0_path = \"KITTI12/training/colored_0/\"+ str(idx).zfill(6) + \"_10.png\"\r\n",
        "  img1_path = \"KITTI12/training/colored_1/\"+ str(idx).zfill(6) + \"_10.png\"\r\n",
        "  gt_path =\"KITTI12/training/disp_occ/\"+ str(idx).zfill(6) + \"_10.png\"\r\n",
        "\r\n",
        "  xidx = idx+200\r\n",
        "  shutil.copy(img0_path , \"KITTI15/training/image_2/\"+ str(xidx).zfill(6) + \"_10.png\" )\r\n",
        "  shutil.copy(img1_path , \"KITTI15/training/image_3/\"+ str(xidx).zfill(6) + \"_10.png\" )\r\n",
        "  shutil.copy(gt_path , \"KITTI15/training/disp_occ_0/\"+ str(xidx).zfill(6) + \"_10.png\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "swL3oHSEDrYY"
      },
      "source": [
        "class KITTI(Dataset):\r\n",
        "    def __init__(self, path, transform=None, train = True):\r\n",
        "        self.transform = transform\r\n",
        "        self.img0_dir = path + \"training/image_2/\"\r\n",
        "        self.img1_dir = path + \"training/image_3/\"\r\n",
        "        self.gt_dir = path + \"training/disp_occ_0/\"\r\n",
        "        self.train = train\r\n",
        "        if train:\r\n",
        "          self.size = int(len(os.listdir(self.gt_dir))*0.8)\r\n",
        "        else:\r\n",
        "          self.size = int(len(os.listdir(self.gt_dir))*0.2)\r\n",
        "          self.remainder = int(len(os.listdir(self.gt_dir))*0.8)\r\n",
        "          \r\n",
        "        self.h = 256\r\n",
        "        self.w = 512\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.size\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if self.train:\r\n",
        "          img0_path = self.img0_dir + str(idx).zfill(6) + \"_10.png\"\r\n",
        "          img1_path = self.img1_dir + str(idx).zfill(6) + \"_10.png\"\r\n",
        "          gt_path = self.gt_dir + str(idx).zfill(6) + \"_10.png\"\r\n",
        "          img0 = Image.open(img0_path).convert('RGB')\r\n",
        "          img1 = Image.open(img1_path).convert('RGB')\r\n",
        "          gt = np.ascontiguousarray(Image.open(gt_path), dtype=np.float32)/256\r\n",
        "          w,h  = img0.size\r\n",
        "          self.r_h = random.randint(0,h-self.h)\r\n",
        "          self.r_w = random.randint(0,w-self.w)\r\n",
        "          img0 = img0.crop((self.r_w,self.r_h, self.r_w + self.w,self.r_h + self.h))\r\n",
        "          img1 = img1.crop((self.r_w,self.r_h, self.r_w + self.w,self.r_h + self.h))\r\n",
        "          gt =  gt[self.r_h:self.r_h+self.h, self.r_w:self.r_w + self.w ]\r\n",
        "          if self.transform:\r\n",
        "            img0 = self.transform(img0)\r\n",
        "            img1 = self.transform(img1)\r\n",
        "          return img0, img1, gt\r\n",
        "        else:\r\n",
        "          idx += self.remainder\r\n",
        "          img0_path = self.img0_dir + str(idx).zfill(6) + \"_10.png\"\r\n",
        "          img1_path = self.img1_dir + str(idx).zfill(6) + \"_10.png\"\r\n",
        "          gt_path = self.gt_dir + str(idx).zfill(6) + \"_10.png\"\r\n",
        "          img0 = Image.open(img0_path).convert('RGB')\r\n",
        "          img1 = Image.open(img1_path).convert('RGB')\r\n",
        "          w,h  = img0.size\r\n",
        "          img0 = img0.crop((w-1232, h-368, w, h))\r\n",
        "          img1 = img1.crop((w-1232, h-368, w, h))\r\n",
        "          gt = Image.open(gt_path)\r\n",
        "          gt = gt.crop((w-1232, h-368, w, h))\r\n",
        "          gt = np.ascontiguousarray(gt,dtype=np.float32)/256\r\n",
        "          if self.transform:\r\n",
        "            img0 = self.transform(img0)\r\n",
        "            img1 = self.transform(img1)\r\n",
        "          return img0, img1, gt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a0NiwAfoDtmT"
      },
      "source": [
        "normalize = {'mean': [0.485, 0.456, 0.406],\r\n",
        "                   'std': [0.229, 0.224, 0.225]}\r\n",
        "input_transforms = torchvision.transforms.Compose([transforms.ToTensor(),\r\n",
        "                                             transforms.Normalize(**normalize)])\r\n",
        "test_dataset = KITTI('./KITTI15/', transform=input_transforms, train = False)\r\n",
        "test_Loader = DataLoader(test_dataset, batch_size= 1, shuffle= False, num_workers= 4, drop_last=False)\r\n",
        "print('Test Dataset Size:', len(test_dataset))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yMnv6HQxDvR2"
      },
      "source": [
        "train_dataset = KITTI('./KITTI15/', transform=input_transforms,train=True)\r\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, pin_memory=True, shuffle=True, num_workers=4)\r\n",
        "\r\n",
        "print('Train Dataset Size:', len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxC1EFWbG_T5"
      },
      "source": [
        "## Create Basic Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g4pSPTe7_3x"
      },
      "source": [
        "Here we define some functions and classes from submodule.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZVo8MjkL0D5P"
      },
      "source": [
        "def conv_bn(dim, in_planes, out_planes, kernel_size, stride, pad, dilation=None):\n",
        "  if dim == 2:\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_planes, out_channels=out_planes, kernel_size=kernel_size, stride=stride, padding=dilation if dilation > 1 else pad, dilation=dilation, bias=False),\n",
        "        nn.BatchNorm2d(out_planes)\n",
        "    )\n",
        "  elif dim == 3:\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(in_channels=in_planes, out_channels=out_planes, kernel_size=kernel_size, padding=pad, stride=stride, bias=False),\n",
        "        nn.BatchNorm3d(out_planes)\n",
        "    )  \n",
        "\n",
        "class DisparityRegression(nn.Module):\n",
        "  def __init__(self, max_disp):\n",
        "    super(DisparityRegression, self).__init__()\n",
        "    self.disp = Variable(torch.Tensor(np.reshape(np.array(range(max_disp)), [1, max_disp, 1, 1])).cuda(), requires_grad=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    disp = self.disp.repeat(x.size()[0], 1, x.size()[2], x.size()[3])\n",
        "    out = torch.sum(x*disp, 1)\n",
        "\n",
        "    return out\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv_sc = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
        "        self.bn_sc = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.bn1(self.conv1(x)))\n",
        "        y = F.relu(self.bn2(self.conv2(y)))\n",
        "        y = self.bn3(self.conv3(y))\n",
        "\n",
        "        x = self.conv_sc(x)\n",
        "        x = self.bn_sc(x)\n",
        "\n",
        "        y += x\n",
        "        y = F.relu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class IdentityBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(IdentityBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.bn1(self.conv1(x)))\n",
        "        y = self.bn2(self.conv2(y))\n",
        "        y += x\n",
        "        y = F.relu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class Feature(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Feature, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Sequential(ConvBlock(3,32,3,1),\n",
        "                                  IdentityBlock(32),\n",
        "                                  IdentityBlock(32),\n",
        "                                  IdentityBlock(32),\n",
        "                                  IdentityBlock(32),\n",
        "                                  ConvBlock(32,64,3,1),\n",
        "                                  IdentityBlock(64),\n",
        "                                  IdentityBlock(64),\n",
        "                                  IdentityBlock(64),\n",
        "                                  IdentityBlock(64),\n",
        "                                  )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(ConvBlock(3,32,3,1),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          ConvBlock(32,64,3,1),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(ConvBlock(3,32,3,1),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          ConvBlock(32,64,3,1),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          )\n",
        "        \n",
        "        self.conv4 = nn.Sequential(ConvBlock(3,32,3,1),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          IdentityBlock(32),\n",
        "                          ConvBlock(32,64,3,1),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          IdentityBlock(64),\n",
        "                          )\n",
        "\n",
        "        self.final_conv = nn.Sequential(ConvBlock(64*4, 128, 3, 1),\n",
        "                                        IdentityBlock(128),\n",
        "                                        IdentityBlock(128),\n",
        "                                        IdentityBlock(128),\n",
        "                                        IdentityBlock(128),\n",
        "                                        ConvBlock(128, 64, 3, 1),\n",
        "                                        IdentityBlock(64),\n",
        "                                        IdentityBlock(64),\n",
        "                                        IdentityBlock(64),\n",
        "                                        IdentityBlock(64),\n",
        "                                        nn.Conv2d(64,32,1)\n",
        "                                        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(F.avg_pool2d(x, 4))\n",
        "        x2 = self.conv2(F.avg_pool2d(x, 8))\n",
        "        x3 = self.conv3(F.avg_pool2d(x, 16))\n",
        "        x4 = self.conv4(F.avg_pool2d(x, 32))\n",
        "\n",
        "        x2 = F.interpolate(x2, (x1.shape[2], x1.shape[3]), mode = 'bilinear')\n",
        "        x3 = F.interpolate(x3, (x1.shape[2], x1.shape[3]), mode = 'bilinear')\n",
        "        x4 = F.interpolate(x4, (x1.shape[2], x1.shape[3]), mode = 'bilinear')\n",
        "\n",
        "        y = torch.cat((x1,x2,x3,x4), dim=1)\n",
        "        y = F.dropout2d(y)\n",
        "        y = self.final_conv(y)\n",
        "\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm6c7Xhf8Is3"
      },
      "source": [
        "class PSMNet(nn.Module):\n",
        "  def __init__(self, max_disp):\n",
        "    super(PSMNet, self).__init__()\n",
        "    self.maxdisp = max_disp\n",
        "    self.feature_extraction = Feature()\n",
        "\n",
        "    self.res0 = nn.Sequential(\n",
        "      conv_bn(3, 64, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.res1 = nn.Sequential(\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "    )\n",
        "    self.res2 = nn.Sequential(\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      conv_bn(3, 32, 32, 3, 1, 1)\n",
        "    )\n",
        "    self.res3 = nn.Sequential(\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True), \n",
        "      conv_bn(3, 32, 32, 3, 1, 1)\n",
        "    )\n",
        "    self.res4 = nn.Sequential(\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      conv_bn(3, 32, 32, 3, 1, 1)\n",
        "    )\n",
        "    self.classify = nn.Sequential(\n",
        "      conv_bn(3, 32, 32, 3, 1, 1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv3d(32, 1, kernel_size=3, padding=1, stride=1, bias=False)\n",
        "    )\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, np.sqrt(2. / n))\n",
        "      elif isinstance(m, nn.Conv3d):\n",
        "        n = m.kernel_size[0] * m.kernel_size[1]*m.kernel_size[2] * m.out_channels\n",
        "        m.weight.data.normal_(0, np.sqrt(2. / n))\n",
        "      elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm3d):\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "  def forward(self, left, right):\n",
        "    ref_img_fea = self.feature_extraction(left)\n",
        "    target_img_fea  = self.feature_extraction(right)\n",
        "\n",
        "    cost = Variable(torch.FloatTensor(ref_img_fea.size()[0], ref_img_fea.size()[1]*2, self.maxdisp//4,  ref_img_fea.size()[2],  ref_img_fea.size()[3]).zero_(), volatile= not self.training).cuda()\n",
        "\n",
        "    for i in range(self.maxdisp//4):\n",
        "      if i > 0:\n",
        "        cost[:, :ref_img_fea.size()[1], i, :,i:] = ref_img_fea[:,:,:,i:]\n",
        "        cost[:, ref_img_fea.size()[1]:, i, :,i:] = target_img_fea[:,:,:,:-i]\n",
        "      else:\n",
        "        cost[:, :ref_img_fea.size()[1], i, :,:] = ref_img_fea\n",
        "        cost[:, ref_img_fea.size()[1]:, i, :,:] = target_img_fea\n",
        "    cost = cost.contiguous()\n",
        "\n",
        "    cost0 = self.res0(cost)\n",
        "    cost0 = self.res1(cost0) + cost0\n",
        "    cost0 = self.res2(cost0) + cost0 \n",
        "    cost0 = self.res3(cost0) + cost0 \n",
        "    cost0 = self.res4(cost0) + cost0\n",
        "\n",
        "    cost = self.classify(cost0)\n",
        "    cost = F.interpolate(cost, [self.maxdisp,left.size()[2], left.size()[3]], mode='trilinear', align_corners=False)\n",
        "    cost = torch.squeeze(cost, 1)\n",
        "    pred = F.softmax(cost)\n",
        "    pred = DisparityRegression(self.maxdisp)(pred)\n",
        "\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3OjAfZXHbce"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYIgp7v3Ha90"
      },
      "source": [
        "# Define network and training parameters\n",
        "torch.cuda.empty_cache()\n",
        "model = PSMNet(192)\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "num_epochs = 100\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX7hl07q9axz"
      },
      "source": [
        "def Test_Acc(model2,test_loader):\n",
        "  def test(imgL,imgR,disp_true):\n",
        "\n",
        "        model2.eval()\n",
        "        imgL   = Variable(torch.FloatTensor(imgL))\n",
        "        imgR   = Variable(torch.FloatTensor(imgR))   \n",
        "        imgL, imgR = imgL.cuda(), imgR.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output3 = model2(imgL,imgR)\n",
        "\n",
        "        pred_disp = output3.data.cpu()\n",
        "        true_disp = disp_true.clone()\n",
        "        \n",
        "        array = np.zeros(true_disp.shape)\n",
        "        array[true_disp>0] = 1\n",
        "\n",
        "        greater_than_one = len(array[array==1])\n",
        "\n",
        "        disp_true = np.abs(true_disp-pred_disp.numpy())\n",
        "        disp_true = disp_true*array\n",
        "        error = len(disp_true[disp_true>3])\n",
        "\n",
        "        return float(error)/float(greater_than_one)\n",
        "\n",
        "  Error = []\n",
        "  for i, (imgL, imgR, disp_L) in enumerate(test_Loader):\n",
        "        Error.append(1-test(imgL,imgR,disp_L))\n",
        "\n",
        "  print(f'Final Accuracy: {np.mean(np.array(Error))}')\n",
        "  return np.mean(np.array(Error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r8zod3Aq0tw"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "pytorch_total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(pytorch_total_params,pytorch_total_trainable_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBoP2mVTICCB",
        "scrolled": false
      },
      "source": [
        "# Train loop\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from google.colab import files\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.05, patience=5, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n",
        "model.train()\n",
        "avg_loss = []\n",
        "start_time = time.time()\n",
        "Acc = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_train_loss = 0\n",
        "    for i, (imgL, imgR, disp_L) in enumerate(train_loader):\n",
        "      imgL = Variable(torch.FloatTensor(imgL)).to(device)\n",
        "      imgR = Variable(torch.FloatTensor(imgR)).to(device)   \n",
        "      disp_L = Variable(torch.FloatTensor(disp_L)).to(device)\n",
        "\n",
        "      mask = (disp_L > 0)\n",
        "      mask.detach_()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      out = model(imgL, imgR)\n",
        "      out = torch.squeeze(out, 1)\n",
        "      loss = F.smooth_l1_loss(out[mask], disp_L[mask], size_average=True)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      avg_loss.append(loss.item())\n",
        "      if i%5==0:\n",
        "        print('Epoch: {0}, Iter: {1}, Training Loss: {2}'.format(epoch, i, loss))\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      del imgL\n",
        "      del imgR\n",
        "      del disp_L\n",
        "      del out\n",
        "      del loss\n",
        "\n",
        "\n",
        "    scheduler.step(np.mean(avg_loss))\n",
        "    print(f'Scheduler saw loss: {np.mean(avg_loss)}')\n",
        "    print(f'Time: {(time.time()-start_time)/60} \\n') \n",
        "    model.eval()\n",
        "    Acc.append(Test_Acc(model,test_Loader))\n",
        "    \n",
        "    model.train()\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Saving the model at Epoch: {epoch}, Average Loss: {np.mean(avg_loss)} as Model_V2_Epoch_{epoch}')\n",
        "      torch.save(model.state_dict(), f'Model_V2_Epoch_{epoch}.pt')\n",
        "      #files.download(f'Model_V2_Epoch_{epoch}.pt')\n",
        "      index = [f'Epoch {i}' for i in range(len(Acc))]\n",
        "      Accuracy_Values = {f'Test Accuracy':Acc}\n",
        "#       df_accuracy = pd.DataFrame(Accuracy_Values,index=index)\n",
        "#       df_accuracy.to_csv(f'Accuracy_Values_Epoch_{epoch}.csv')\n",
        "#       files.download(f'Accuracy_Values_Epoch_{epoch}.csv')\n",
        "\n",
        "    avg_loss = []\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLvFJLbmJLJv"
      },
      "source": [
        "torch.save(model.state_dict(), f'model_V4_Modified_Epoch_{epoch}.pt')\r\n",
        "torch.save(optimizer.state_dict(), 'optimizer.pt')\r\n",
        "torch.save(scheduler.state_dict(), 'scheduler.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiT54xRwukWW"
      },
      "source": [
        "model2 = PSMNet(192)\n",
        "model2.load_state_dict(torch.load('model_V1_Epoch_86.pt'));\n",
        "model2.eval()\n",
        "device = torch.device(\"cuda\")\n",
        "model2.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u1oGoXgamwX"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg6SeB3QdO0N"
      },
      "source": [
        "class KITTI_submission(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.transform = transform\n",
        "        self.img0_dir = path + \"training/left/\"\n",
        "        self.img1_dir = path + \"training/right/\"\n",
        "        self.gt_dir = path + \"training/disp/\"\n",
        "        self.size = int(len(os.listdir(self.gt_dir))*0.2)\n",
        "        self.remainder = int(len(os.listdir(self.gt_dir))*0.8)\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    def __getitem__(self, idx):\n",
        "          idx += self.remainder\n",
        "          img0_path = self.img0_dir + str(idx).zfill(6) + \"_10.png\"\n",
        "          img1_path = self.img1_dir + str(idx).zfill(6) + \"_10.png\"\n",
        "          gt_path = self.gt_dir + str(idx).zfill(6) + \"_10.png\"\n",
        "          img0 = Image.open(img0_path).convert('RGB')\n",
        "          img1 = Image.open(img1_path).convert('RGB')           \n",
        "          w,h  = img0.size\n",
        "          img0 = img0.crop((w-416, h-320, w, h))\n",
        "          img1 = img1.crop((w-416, h-320, w, h))\n",
        "          gt = Image.open(gt_path)\n",
        "          gt = gt.crop((w-416, h-320, w, h))  \n",
        "          gt = np.ascontiguousarray(gt,dtype=np.float32)\n",
        "          if self.transform:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "          return img0, img1, gt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se3i1ucYdO0N"
      },
      "source": [
        "normalize = {'mean': [0.485, 0.456, 0.406],\n",
        "                   'std': [0.229, 0.224, 0.225]}\n",
        "input_transforms = torchvision.transforms.Compose([transforms.ToTensor(),\n",
        "                                             transforms.Normalize(**normalize)])\n",
        "submission_dataset = KITTI('./CMU_CLEAN/', transform=input_transforms)\n",
        "submission_loader = DataLoader(submission_dataset, batch_size= 1, shuffle= False, num_workers= 4, drop_last=False)\n",
        "print('Test Dataset Size:', len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O-QV4fIdO0N"
      },
      "source": [
        "def predict(i, imgL,imgR, DispL):\n",
        "\n",
        "    model.eval()\n",
        "    imgL   = Variable(torch.FloatTensor(imgL))\n",
        "    imgR   = Variable(torch.FloatTensor(imgR))   \n",
        "    imgL, imgR = imgL.cuda(), imgR.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output3 = model(imgL,imgR)\n",
        "\n",
        "    pred_disp = np.squeeze(output3.data.cpu().numpy())\n",
        "    true_disp = np.squeeze(DispL.data.cpu().numpy())\n",
        "    \n",
        "    pred_disp = Image.fromarray((pred_disp*256).astype('uint16'))\n",
        "    pred_disp.save(\"pred/\"+str(i)+\".png\")\n",
        "    \n",
        "    true_disp = Image.fromarray((true_disp*256).astype('uint16'))\n",
        "    true_disp.save(\"GT/\" + str(i)+\".png\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDNQZlbadO0N"
      },
      "source": [
        "for i, (imgL, imgR, DispL) in enumerate(submission_loader):\n",
        "    print(\"Inferring\",i)\n",
        "    predict(i, imgL, imgR, DispL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}